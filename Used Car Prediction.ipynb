{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import visualizations package\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import profiling package\n",
    "import ydata_profiling as pp\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "#set of techniques used in statistics and data analysis to stabilize variance and make the data more normally distributed or to make the relationship b/n variables more linear\n",
    "from sklearn.preprocessing import PowerTransformer \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats import diagnostic as diag\n",
    "from statsmodels.compat import lzip\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('train-data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('Seats', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~(data['Kilometers_Driven'] > 400000)]\n",
    "data = data[~(data['Mileage'] == '0.0 kmpl')]\n",
    "data = data[~(data['Seats'] == 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([data.columns[0], 'Name','New_Price'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "y_train=data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat=data[data.columns[[0,1,3,4,5,9]]]\n",
    "data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_cat=data.iloc[:,[0,1,3,4,5,9]]\n",
    "data_num=data.iloc[:,[2,6,7,8]]\n",
    "data=pd.concat([data,y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through each column in the data_cat DataFrame and grouping by the unique values in column\n",
    "for i in data_cat.columns:                                           \n",
    "    print(data.groupby(i)['Price'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the values in columns of the data_num by whitespace and extracting the second part of the split. Subsequently, it counts the occurrences of each extracted value\n",
    "print(data_num['Mileage'].str.split().str[1].value_counts())\n",
    "print(data_num['Engine'].str.split().str[1].value_counts())\n",
    "print(data_num['Power'].str.split().str[1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mil=[]\n",
    "for i in data_num.Mileage:\n",
    "    if str(i).endswith('km/kg'):\n",
    "        val=i[:-6]\n",
    "        val=float(val)*1.33\n",
    "        mil.append(float(val))\n",
    "    else:\n",
    "        val=i[:-5]\n",
    "        val=float(val)\n",
    "        mil.append(float(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num['Mileage']=mil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num['Engine']=data_num['Engine'].str.split().str[0]\n",
    "data_num['Power']=data_num['Power'].str.split().str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num['Power']=data_num['Power'].replace('null', np.mean(pd.to_numeric(data_num['Power'], errors='coerce')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num['Engine']=data_num['Engine'].astype(float)\n",
    "data_num['Power']=data_num['Power'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create a grid of subplots(6 rows).Each row represents a different categorical column from the data_cat DataFrame.\n",
    "# The count of each unique value in each categorical column is plotted.\n",
    "fig,axes = plt.subplots(nrows=6, figsize=(25,60))\n",
    "for i,j in zip(data_cat.columns, range(0,6,1)):\n",
    "    sns.countplot(x=data_cat[i], ax=axes[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=6, figsize=(25,60))\n",
    "for i,j in zip(data_cat.columns, range(0,6,1)):\n",
    "    sns.violinplot(x=data_cat[i], y=y_train, ax=axes[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=4, figsize=(10,30))\n",
    "for i,j in zip(data_num.columns, range(0,4,1)):\n",
    "    sns.regplot(x=data_num[i], y=y_train, scatter_kws={'s':10}, ax=axes[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat['Fuel_Type'].replace(to_replace=['CNG','LPG'],value='CNG/LPG',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [*range(1998, 2020, 1)]\n",
    "l2 = [*range(1, 23, 1)]\n",
    "year_dict = dict(zip(l1, l2))\n",
    "print(year_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_cols_mapping = [\n",
    "    {\"col\":\"Owner_Type\",    \"mapping\": {'First' : 1, 'Second' : 2, 'Third' : 3, 'Fourth & Above':4}}\n",
    "    ,{\"col\":\"Seats\",    \"mapping\": {0.0 : 0, 2.0 : 2, 4.0 : 4, 5.0 : 5, 6.0 : 6, 7.0 : 7, 8.0 : 8, 9.0 : 9, 10.0 : 10}} \n",
    "    ,{\"col\":\"Year\",    \"mapping\": year_dict},\n",
    "]\n",
    "\n",
    "encoder = ce.ordinal.OrdinalEncoder(mapping = ordinal_cols_mapping,return_df = True)  \n",
    "data_cat = encoder.fit_transform(data_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHotwEncoding with feature name as labels\n",
    "categoryVariableList = ['Location', 'Fuel_Type', 'Transmission']\n",
    "\n",
    "ohe = OneHotEncoder(categories='auto', drop='first', handle_unknown='ignore')\n",
    "feature_arr = ohe.fit_transform(data_cat[categoryVariableList]).toarray()\n",
    "feature_labels = ohe.get_feature_names_out(categoryVariableList)\n",
    "\n",
    "# feature_labels = np.array(feature_labels).ravel()\n",
    "\n",
    "features = pd.DataFrame(feature_arr, columns=feature_labels)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat=pd.concat([data_cat.reset_index(drop=True), features], axis=1)\n",
    "data_cat.drop(columns=categoryVariableList, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying box-cox transformer\n",
    "#This is a family of power transformations that generalize both the square root and logarithm transformations.\n",
    "# The Box-Cox transformation can handle different power values, and the optimal value of the power parameter is typically determined through maximum likelihood estimation\n",
    "\n",
    "pt = PowerTransformer(method='box-cox')\n",
    "data_num2 = pt.fit_transform(data_num+0.0000001)\n",
    "pd.DataFrame({'cols':data_num.columns,'box_cox_lambda':pt.lambdas_})\n",
    "data_num_trans = pd.DataFrame(data_num2,columns=data_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([data_num_trans.reset_index(drop=True), data_cat.reset_index(drop=True)], axis=1)\n",
    "Y_train = y_train.reset_index(drop=True)\n",
    "model_data = pd.concat([X_train,Y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train,Y_train,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    plt.figure(figsize=(18,4))\n",
    "    plt.subplot(131)\n",
    "    sns.distplot(X_train[col])\n",
    "    plt.title(col)\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    stats.probplot(X_train[col],dist ='norm',plot = plt)\n",
    "    plt.title(col)\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    sns.regplot(x=X_train[col],y=Y_train, scatter_kws={'s':10})\n",
    "    plt.title(col)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=X_train.columns.drop(['Seats','Year','Fuel_Type_Diesel','Engine'])\n",
    "a\n",
    "b=X_train[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike sklearn that adds an intercept to our data for the best fit, statsmodel doesn't. We need to add it ourselves.\n",
    "# Remember, we want to predict the price based off our features.\n",
    "# X_train represents our predictor variables, and y our predicted variable.\n",
    "# We need now to add manually the intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # The add_constant function from statsmodels adds a constant term (intercept) to the exogenous variables (independent variables). \n",
    " # This is required when performing linear regression using the Ordinary Least Squares (OLS) method.\n",
    "X_endog = sm.add_constant(b)  \n",
    "\n",
    "# The sm.OLS function initializes a model for ordinary least squares (OLS) regression. \n",
    "# Here:Y_train.ravel() is the dependent variable (response variable) which is flattened (if it's a 2D array) to ensure it's in the correct shape.\n",
    "# X_endog contains the independent variables (features) with an added constant term                            \n",
    "res = sm.OLS(Y_train.ravel(), X_endog)\n",
    "\n",
    "# The fit method computes the OLS regression model. By specifying cov_type='HC1', you're also requesting robust standard errors for the estimated coefficients. The 'HC1' option \n",
    "# refers to the heteroskedasticity-consistent covariance matrix estimator, which is robust to certain violations of classical OLS assumptions, such as heteroskedasticity.\n",
    "model=res.fit(cov_type='HC1')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "sns.heatmap(b.corr(),annot=True,cmap='RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the Variance Inflation Factor (VIF) for each feature in the dataframe b. VIF is used to detect multicollinearity in regression analysis.\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = b.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(b.values, i) for i in range(len(b.columns))]\n",
    "\n",
    "vif_data.sort_values('VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals=model.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_residuals = np.mean(residuals)\n",
    "print(\"Mean of Residuals {}\".format(mean_residuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The het_breuschpagan function conducts the Breusch-Pagan test, which is a test for heteroskedasticity in the residuals of a regression model.\n",
    "# Heteroskedasticity occurs when the variance of the errors is not constant across all levels of the independent variables.\n",
    "X_endog = sm.add_constant(X_train)\n",
    "bp_test = het_breuschpagan(model.resid, X_endog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_test = het_white(model.resid,  model.model.exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['LM Statistic', 'LM-Test p-value', 'F-Statistic', 'F-Test p-value']\n",
    "print(dict(zip(labels, bp_test)))\n",
    "print(dict(zip(labels, white_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['F statistic', 'p-value']\n",
    "test = sms.het_goldfeldquandt(residuals, X_train)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(residuals,kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autocorrelation\n",
    "sm.graphics.tsa.plot_acf(residuals, lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial autocorrelation\n",
    "sm.graphics.tsa.plot_pacf(residuals, lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(diag.acorr_ljungbox(residuals , lags = 40)['lb_pvalue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = lr.predict(X_test)\n",
    "Y_pred_train = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy:\", r2_score(Y_test,Y_pred))\n",
    "print(\"Train accuracy:\", r2_score(Y_train,Y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
